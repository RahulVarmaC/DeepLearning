{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8N1zWWQxAbS-"
      },
      "source": [
        "**Rahul Varma Chintalapati**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNQ7rpqyTzfE"
      },
      "source": [
        "#### Developed by Rahul Varma Chintalapati\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "b1zFvB61UKfq",
        "outputId": "9dd0cd1b-8f22-47e3-c53b-1c04bd2506dc"
      },
      "source": [
        "df=pd.read_csv(\"/content/sample_data/churn.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>churn</th>\n",
              "      <th>accountlength</th>\n",
              "      <th>internationalplan</th>\n",
              "      <th>voicemailplan</th>\n",
              "      <th>numbervmailmessages</th>\n",
              "      <th>totaldayminutes</th>\n",
              "      <th>totaldaycalls</th>\n",
              "      <th>totaldaycharge</th>\n",
              "      <th>totaleveminutes</th>\n",
              "      <th>totalevecalls</th>\n",
              "      <th>totalevecharge</th>\n",
              "      <th>totalnightminutes</th>\n",
              "      <th>totalnightcalls</th>\n",
              "      <th>totalnightcharge</th>\n",
              "      <th>totalintlminutes</th>\n",
              "      <th>totalintlcalls</th>\n",
              "      <th>totalintlcharge</th>\n",
              "      <th>numbercustomerservicecalls</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No</td>\n",
              "      <td>128</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>25</td>\n",
              "      <td>265.1</td>\n",
              "      <td>110</td>\n",
              "      <td>45.07</td>\n",
              "      <td>197.4</td>\n",
              "      <td>99</td>\n",
              "      <td>16.78</td>\n",
              "      <td>244.7</td>\n",
              "      <td>91</td>\n",
              "      <td>11.01</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>No</td>\n",
              "      <td>107</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>26</td>\n",
              "      <td>161.6</td>\n",
              "      <td>123</td>\n",
              "      <td>27.47</td>\n",
              "      <td>195.5</td>\n",
              "      <td>103</td>\n",
              "      <td>16.62</td>\n",
              "      <td>254.4</td>\n",
              "      <td>103</td>\n",
              "      <td>11.45</td>\n",
              "      <td>13.7</td>\n",
              "      <td>3</td>\n",
              "      <td>3.70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>No</td>\n",
              "      <td>137</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "      <td>243.4</td>\n",
              "      <td>114</td>\n",
              "      <td>41.38</td>\n",
              "      <td>121.2</td>\n",
              "      <td>110</td>\n",
              "      <td>10.30</td>\n",
              "      <td>162.6</td>\n",
              "      <td>104</td>\n",
              "      <td>7.32</td>\n",
              "      <td>12.2</td>\n",
              "      <td>5</td>\n",
              "      <td>3.29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>No</td>\n",
              "      <td>84</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "      <td>299.4</td>\n",
              "      <td>71</td>\n",
              "      <td>50.90</td>\n",
              "      <td>61.9</td>\n",
              "      <td>88</td>\n",
              "      <td>5.26</td>\n",
              "      <td>196.9</td>\n",
              "      <td>89</td>\n",
              "      <td>8.86</td>\n",
              "      <td>6.6</td>\n",
              "      <td>7</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>No</td>\n",
              "      <td>75</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "      <td>166.7</td>\n",
              "      <td>113</td>\n",
              "      <td>28.34</td>\n",
              "      <td>148.3</td>\n",
              "      <td>122</td>\n",
              "      <td>12.61</td>\n",
              "      <td>186.9</td>\n",
              "      <td>121</td>\n",
              "      <td>8.41</td>\n",
              "      <td>10.1</td>\n",
              "      <td>3</td>\n",
              "      <td>2.73</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  churn  accountlength  ... totalintlcharge numbercustomerservicecalls\n",
              "0    No            128  ...            2.70                          1\n",
              "1    No            107  ...            3.70                          1\n",
              "2    No            137  ...            3.29                          0\n",
              "3    No             84  ...            1.78                          2\n",
              "4    No             75  ...            2.73                          3\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsOdn9tnUQ9w",
        "outputId": "7804a6c6-0308-419e-97a7-e73687138006"
      },
      "source": [
        "y=df.iloc[:,0].values\n",
        "x=df.iloc[:,1:].values\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[128 'no' 'yes' ... 3 2.7 1]\n",
            " [107 'no' 'yes' ... 3 3.7 1]\n",
            " [137 'no' 'no' ... 5 3.29 0]\n",
            " ...\n",
            " [61 'no' 'no' ... 4 3.67 1]\n",
            " [109 'no' 'no' ... 6 2.3 0]\n",
            " [86 'no' 'yes' ... 16 2.51 0]]\n",
            "['No' 'No' 'No' ... 'No' 'No' 'No']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpNIu3qrVc6X"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# from sklearn.preprocessing import OneHotEncoder# we use this when we cannot add values to the categorical values."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8568fOupeQA",
        "outputId": "f5e43f60-8de3-4a69-a44c-e9c8b95dbc60"
      },
      "source": [
        "le=LabelEncoder()# to transform the target variable\n",
        "y= le.fit_transform(y)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5n5rCVmp7L_",
        "outputId": "9d4efc49-937a-4979-9ffe-48ce6234874a"
      },
      "source": [
        "#from sklearn.compose import ColumnTransformer\n",
        "# one=OneHotEncoder(drop=\"first\")\n",
        "le_x=LabelEncoder()\n",
        "x[:,1]=le.fit_transform(x[:,1])\n",
        "x[:,2]=le.fit_transform(x[:,2])\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[128 0 1 ... 3 2.7 1]\n",
            " [107 0 1 ... 3 3.7 1]\n",
            " [137 0 0 ... 5 3.29 0]\n",
            " ...\n",
            " [61 0 0 ... 4 3.67 1]\n",
            " [109 0 0 ... 6 2.3 0]\n",
            " [86 0 1 ... 16 2.51 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC61CQ8tvW6r"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YO6JyHf7vtcn",
        "outputId": "c40262d1-7848-4fc8-bfc2-a9dc22a590a9"
      },
      "source": [
        "\n",
        "print(x_train[0:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[141 0 1 28 308.0 123 52.36 247.8 128 21.06 152.9 103 6.88 7.4 3 2.0 1]\n",
            " [135 0 0 0 239.9 91 40.78 177.1 104 15.05 217.2 118 9.77 5.9 3 1.59 2]\n",
            " [172 0 1 47 274.9 102 46.73 186.6 118 15.86 245.0 123 11.03 8.8 2 2.38 1]\n",
            " [54 0 1 24 92.3 88 15.69 193.1 98 16.41 99.3 119 4.47 11.6 3 3.13 2]\n",
            " [40 0 0 0 115.7 105 19.67 127.8 113 10.86 107.5 91 4.84 9.3 6 2.51 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx89Hn9bvwNX"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "x_train=sc.fit_transform(x_train)\n",
        "x_test=sc.fit_transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QvoosLJwHdw"
      },
      "source": [
        "ann = tf.keras.models.Sequential()\n",
        "ann.add(tf.keras.layers.Dense(units=35, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=35, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=35, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=1))\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "ann.compile(optimizer = opt, loss = 'mean_absolute_error', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYE6MQyR2ssf"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG8H1Y3fxHIn",
        "outputId": "1b0ff9ff-416b-4441-cef8-c3c32887b42b"
      },
      "source": [
        "ann.fit(x_train, y_train, batch_size = 32, epochs = 100)\n",
        "# from keras.callbacks import CSVLogger\n",
        "# csv_logger = CSVLogger(\"model_history_log.csv\", append=True)\n",
        "# ann.fit_generator(x_train, y_train, batch_size = 32, epochs = 100,callbacks=[csv_logger])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "110/110 [==============================] - 1s 3ms/step - loss: 0.2212 - accuracy: 0.8509\n",
            "Epoch 2/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.1681 - accuracy: 0.8557\n",
            "Epoch 3/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.1542 - accuracy: 0.8634\n",
            "Epoch 4/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.1397 - accuracy: 0.8831\n",
            "Epoch 5/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.1300 - accuracy: 0.8989\n",
            "Epoch 6/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.1254 - accuracy: 0.9006\n",
            "Epoch 7/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.1193 - accuracy: 0.9029\n",
            "Epoch 8/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.1162 - accuracy: 0.9046\n",
            "Epoch 9/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.1130 - accuracy: 0.9057\n",
            "Epoch 10/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.1088 - accuracy: 0.9097\n",
            "Epoch 11/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.1031 - accuracy: 0.9126\n",
            "Epoch 12/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0984 - accuracy: 0.9197\n",
            "Epoch 13/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0944 - accuracy: 0.9217\n",
            "Epoch 14/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0926 - accuracy: 0.9260\n",
            "Epoch 15/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 0.9266\n",
            "Epoch 16/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0858 - accuracy: 0.9297\n",
            "Epoch 17/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0850 - accuracy: 0.9346\n",
            "Epoch 18/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0813 - accuracy: 0.9366\n",
            "Epoch 19/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0784 - accuracy: 0.9389\n",
            "Epoch 20/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0774 - accuracy: 0.9403\n",
            "Epoch 21/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0764 - accuracy: 0.9423\n",
            "Epoch 22/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0747 - accuracy: 0.9463\n",
            "Epoch 23/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0713 - accuracy: 0.9463\n",
            "Epoch 24/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.9469\n",
            "Epoch 25/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.9494\n",
            "Epoch 26/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9483\n",
            "Epoch 27/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.9497\n",
            "Epoch 28/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.9514\n",
            "Epoch 29/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.9514\n",
            "Epoch 30/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.9523\n",
            "Epoch 31/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9540\n",
            "Epoch 32/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0607 - accuracy: 0.9554\n",
            "Epoch 33/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.9551\n",
            "Epoch 34/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0587 - accuracy: 0.9560\n",
            "Epoch 35/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.9560\n",
            "Epoch 36/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.9566\n",
            "Epoch 37/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.9600\n",
            "Epoch 38/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.9594\n",
            "Epoch 39/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9591\n",
            "Epoch 40/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.9594\n",
            "Epoch 41/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9606\n",
            "Epoch 42/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9614\n",
            "Epoch 43/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9623\n",
            "Epoch 44/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0505 - accuracy: 0.9609\n",
            "Epoch 45/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 0.9626\n",
            "Epoch 46/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0488 - accuracy: 0.9637\n",
            "Epoch 47/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 0.9640\n",
            "Epoch 48/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9634\n",
            "Epoch 49/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 0.9640\n",
            "Epoch 50/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0472 - accuracy: 0.9637\n",
            "Epoch 51/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9651\n",
            "Epoch 52/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0456 - accuracy: 0.9657\n",
            "Epoch 53/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 0.9649\n",
            "Epoch 54/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0447 - accuracy: 0.9649\n",
            "Epoch 55/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9649\n",
            "Epoch 56/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0453 - accuracy: 0.9663\n",
            "Epoch 57/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9657\n",
            "Epoch 58/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0435 - accuracy: 0.9663\n",
            "Epoch 59/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.9660\n",
            "Epoch 60/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0431 - accuracy: 0.9669\n",
            "Epoch 61/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0431 - accuracy: 0.9674\n",
            "Epoch 62/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9663\n",
            "Epoch 63/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0426 - accuracy: 0.9671\n",
            "Epoch 64/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.9671\n",
            "Epoch 65/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0421 - accuracy: 0.9680\n",
            "Epoch 66/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0418 - accuracy: 0.9677\n",
            "Epoch 67/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9680\n",
            "Epoch 68/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9683\n",
            "Epoch 69/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0418 - accuracy: 0.9686\n",
            "Epoch 70/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 0.9691\n",
            "Epoch 71/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 0.9706\n",
            "Epoch 72/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9697\n",
            "Epoch 73/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.9694\n",
            "Epoch 74/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9689\n",
            "Epoch 75/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9697\n",
            "Epoch 76/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9700\n",
            "Epoch 77/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9709\n",
            "Epoch 78/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9706\n",
            "Epoch 79/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9709\n",
            "Epoch 80/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 0.9711\n",
            "Epoch 81/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0374 - accuracy: 0.9720\n",
            "Epoch 82/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9717\n",
            "Epoch 83/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9726\n",
            "Epoch 84/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.9726\n",
            "Epoch 85/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9720\n",
            "Epoch 86/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9723\n",
            "Epoch 87/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0372 - accuracy: 0.9723\n",
            "Epoch 88/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0364 - accuracy: 0.9726\n",
            "Epoch 89/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9723\n",
            "Epoch 90/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.9723\n",
            "Epoch 91/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 0.9723\n",
            "Epoch 92/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 0.9726\n",
            "Epoch 93/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9729\n",
            "Epoch 94/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9729\n",
            "Epoch 95/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.9717\n",
            "Epoch 96/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9723\n",
            "Epoch 97/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9740\n",
            "Epoch 98/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9726\n",
            "Epoch 99/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9731\n",
            "Epoch 100/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0347 - accuracy: 0.9734\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff05c234490>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3BrmDToxIIv",
        "outputId": "8a984965-4c7f-44b4-e9f3-ef6210a386ac"
      },
      "source": [
        "\n",
        "y_pred=ann.predict(x_test)\n",
        "y_pred=y_pred>0.5\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " ...\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOt7QxRhxhEH",
        "outputId": "dafac61f-53a4-41e7-fcb7-4edf004c482f"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "sm=confusion_matrix(y_test,y_pred)\n",
        "print(sm)\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1280   18]\n",
            " [  68  134]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9426666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm5vHiVVAXxE"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alhgEOJHxjtP",
        "outputId": "5e0720f2-e179-4ebe-8f31-c74c9e4219df"
      },
      "source": [
        "#print(ann.trainable_variables) \n",
        "weights=ann.trainable_variables\n",
        "print(weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Variable 'dense_36/kernel:0' shape=(17, 35) dtype=float32, numpy=\n",
            "array([[ 2.30992049e-01,  3.92830372e-01,  1.41549170e-01,\n",
            "         1.19312979e-01,  2.77320072e-02, -9.24788341e-02,\n",
            "         1.71066672e-01,  2.13164344e-01,  6.81141019e-02,\n",
            "        -9.34915394e-02, -2.27422081e-02,  4.59666438e-02,\n",
            "         5.26493229e-02,  1.81887988e-02, -2.01496989e-01,\n",
            "        -2.75525283e-02,  2.24177632e-02,  1.01283625e-01,\n",
            "         7.25593567e-02, -2.37599984e-01,  2.15431765e-01,\n",
            "        -4.52848151e-02, -6.97832033e-02,  2.27818370e-01,\n",
            "        -1.23218305e-01,  2.49885961e-01, -2.56238192e-01,\n",
            "         2.06105009e-01,  5.28039187e-02,  1.52577281e-01,\n",
            "         2.04400182e-01,  2.90899575e-01, -1.87213644e-02,\n",
            "        -1.76485583e-01,  1.66108713e-01],\n",
            "       [-3.17984492e-01,  2.37577483e-01,  1.12679683e-01,\n",
            "         5.54797947e-02,  2.12264642e-01,  1.10269591e-01,\n",
            "        -4.90552366e-01, -2.87209570e-01, -5.20183966e-02,\n",
            "        -2.82388210e-01,  2.05647990e-01, -3.96600008e-01,\n",
            "        -2.48428032e-01,  3.94085832e-02, -5.26731797e-02,\n",
            "         5.33563457e-02,  2.87140429e-01,  3.70802313e-01,\n",
            "         2.13283882e-01, -3.77853721e-01, -2.92039931e-01,\n",
            "        -4.13132250e-01, -7.05933049e-02, -1.37312010e-01,\n",
            "        -1.42526686e-01, -2.27413606e-02, -5.06390110e-02,\n",
            "         2.77776904e-02, -2.56713361e-01,  1.36866361e-01,\n",
            "        -3.35049406e-02, -6.20045781e-01, -2.08786875e-01,\n",
            "        -2.64109403e-01, -8.95650685e-03],\n",
            "       [-1.50369242e-01,  1.73338503e-01,  1.09192148e-01,\n",
            "        -3.72816026e-01, -2.34206721e-01, -6.02385588e-03,\n",
            "        -2.76241064e-01,  1.66475117e-01,  1.34715736e-01,\n",
            "         2.47342065e-01, -1.48821762e-02, -1.32002458e-01,\n",
            "        -4.04780433e-02,  1.75500378e-01,  4.44754004e-01,\n",
            "         4.62027788e-01, -1.95053257e-02,  2.26394683e-01,\n",
            "        -4.48607177e-01, -1.30149007e-01, -3.59653503e-01,\n",
            "        -3.12690884e-01, -8.08788717e-01,  3.14514279e-01,\n",
            "         4.97520529e-02, -2.18079433e-01,  2.64294475e-01,\n",
            "        -1.54686004e-01, -6.87398538e-02, -5.05263619e-02,\n",
            "        -9.85307470e-02,  4.18419093e-01, -2.76992936e-02,\n",
            "         2.55799711e-01,  1.41721785e-01],\n",
            "       [-1.05184630e-01,  1.36796813e-02, -2.98354834e-01,\n",
            "        -1.19250067e-01, -1.07596084e-01, -1.00981042e-01,\n",
            "        -3.65633398e-01,  3.51590544e-01, -2.42664695e-01,\n",
            "        -3.25638235e-01, -1.34438470e-01, -1.58079490e-01,\n",
            "        -1.06358655e-01,  1.21570021e-01,  2.27091238e-01,\n",
            "        -1.59605384e-01,  1.11685224e-01,  1.86067402e-01,\n",
            "         7.73244351e-02, -2.80399680e-01,  2.19954289e-02,\n",
            "        -1.88845500e-01, -3.73644054e-01, -2.31983885e-01,\n",
            "        -9.17141736e-02,  2.71697521e-01,  3.64991158e-01,\n",
            "         2.25090906e-01, -3.39814015e-02, -3.88409048e-01,\n",
            "         8.55852216e-02,  3.25703621e-01,  1.87254667e-01,\n",
            "        -1.59828495e-02,  1.96255714e-01],\n",
            "       [ 8.42656102e-03, -2.08579391e-01,  2.02255026e-01,\n",
            "        -1.10178567e-01,  2.23628923e-01,  5.47307551e-01,\n",
            "        -2.61299640e-01, -3.29576880e-01,  6.28987700e-02,\n",
            "         2.41399422e-01, -1.38576165e-01, -3.67419332e-01,\n",
            "         2.90885925e-01,  1.76105604e-01,  1.08291715e-01,\n",
            "         1.06129162e-01,  7.74392858e-02, -3.01274329e-01,\n",
            "         1.69194892e-01,  2.84938931e-01, -1.73977748e-01,\n",
            "        -2.14250401e-01,  1.92435415e-04,  4.60860938e-01,\n",
            "        -3.45174164e-01, -3.51310790e-01,  5.07803671e-02,\n",
            "        -2.50335515e-01,  1.78450555e-01, -2.22313419e-01,\n",
            "        -3.40104699e-01, -2.69229263e-01, -2.49880135e-01,\n",
            "         1.66958079e-01,  2.26887688e-02],\n",
            "       [-4.11532708e-02,  1.35014979e-02,  9.58065316e-02,\n",
            "        -1.92426473e-01,  1.62458718e-01,  2.00769484e-01,\n",
            "         1.16329901e-01, -6.51130080e-02,  1.13744754e-03,\n",
            "        -1.36814252e-01,  1.12438425e-01,  2.65874118e-01,\n",
            "        -9.58802328e-02, -1.97832271e-01,  1.10127263e-01,\n",
            "         1.79380491e-01,  7.89691880e-02,  1.79730371e-01,\n",
            "         1.33969545e-01,  1.99520320e-01,  1.55028224e-01,\n",
            "         1.21119224e-01,  3.33680771e-03, -1.82742134e-01,\n",
            "         1.57519672e-02,  1.60776928e-01,  1.18615903e-01,\n",
            "         2.87889272e-01, -1.46734178e-01,  1.25511706e-01,\n",
            "         2.65490919e-01, -1.66702755e-02,  1.71694886e-02,\n",
            "         1.08557768e-01,  2.03061029e-01],\n",
            "       [-1.47456795e-01,  1.79386303e-01, -2.77994424e-01,\n",
            "         3.82548608e-02, -3.24984223e-01,  2.57099252e-02,\n",
            "        -3.77646029e-01,  1.97260931e-01,  5.46475768e-01,\n",
            "        -2.10324243e-01, -1.62115648e-01, -2.64763474e-01,\n",
            "         2.71810621e-01,  2.30471790e-02, -1.16801284e-01,\n",
            "        -2.37705708e-01, -5.23998439e-01,  1.52988255e-01,\n",
            "         4.36841309e-01,  1.96634009e-01, -5.33512890e-01,\n",
            "        -1.12534739e-01, -2.94766694e-01,  3.54142278e-01,\n",
            "        -9.41344425e-02,  1.74798086e-01,  2.91025173e-02,\n",
            "        -2.87675828e-01, -3.85371834e-01, -1.77246705e-01,\n",
            "         2.84766942e-01, -1.22714646e-01, -2.77290732e-01,\n",
            "        -1.42748475e-01,  3.17684174e-01],\n",
            "       [ 1.25313267e-01, -1.89579651e-01,  6.63283244e-02,\n",
            "        -4.65140454e-02,  1.16131872e-01, -1.24300532e-01,\n",
            "        -1.94127455e-01,  2.85569966e-01,  3.71092379e-01,\n",
            "        -1.93595171e-01, -2.38328531e-01, -2.64459908e-01,\n",
            "         3.27821746e-02, -1.91721126e-01, -8.86611491e-02,\n",
            "        -2.86359459e-01,  5.22441491e-02, -2.60203093e-01,\n",
            "         9.38173234e-02, -7.02685416e-02, -1.30918920e-01,\n",
            "        -1.01421148e-01,  9.39389095e-02,  3.28599900e-01,\n",
            "        -2.15396866e-01,  1.02993295e-01, -7.83842057e-02,\n",
            "        -6.59141093e-02, -3.07413906e-01,  1.05384700e-01,\n",
            "        -2.95393586e-01,  1.18010871e-01, -1.18352704e-01,\n",
            "        -2.31957629e-01,  1.59743652e-01],\n",
            "       [-1.51034534e-01,  8.81149713e-03,  6.59088790e-03,\n",
            "        -1.25947997e-01,  2.18660623e-01, -1.59437373e-01,\n",
            "         7.55740330e-02, -1.40401849e-03,  1.54206390e-02,\n",
            "        -1.40787542e-01,  1.24282278e-01, -3.23095508e-02,\n",
            "        -6.70631751e-02,  2.19844896e-02, -3.68845493e-01,\n",
            "         1.81268945e-01, -1.78034917e-01,  3.64978194e-01,\n",
            "         3.91617464e-03,  3.30584377e-01,  2.04454988e-01,\n",
            "        -1.81194812e-01,  6.80055469e-02, -7.84943253e-02,\n",
            "        -1.00934938e-01,  2.37485379e-01,  2.28424057e-01,\n",
            "         1.18536614e-01,  4.07681435e-01, -1.68108106e-01,\n",
            "        -2.38665193e-01,  1.20126314e-01,  1.89320683e-01,\n",
            "        -2.76825219e-01,  3.48315924e-01],\n",
            "       [ 2.06004363e-02, -2.92184092e-02,  7.14788139e-02,\n",
            "        -2.17835113e-01, -9.85184759e-02,  2.62349963e-01,\n",
            "        -1.56559780e-01,  7.62565657e-02,  1.28576849e-02,\n",
            "         3.04711014e-01,  1.57620892e-01, -1.30703868e-02,\n",
            "        -1.03505902e-01, -1.11743942e-01,  6.64732382e-02,\n",
            "        -3.21354508e-01, -2.48711348e-01,  2.19873860e-01,\n",
            "         2.98459649e-01,  2.32666343e-01, -2.32450783e-01,\n",
            "         3.12545933e-02, -7.75582120e-02,  2.24959210e-01,\n",
            "        -3.37734073e-01, -1.45368591e-01,  3.13575745e-01,\n",
            "        -1.76330164e-01,  6.17949292e-02, -2.04188213e-01,\n",
            "        -6.20058179e-02,  5.10673299e-02, -2.17357725e-01,\n",
            "        -2.69330233e-01,  7.81714842e-02],\n",
            "       [-2.06157222e-01,  3.61552387e-01,  4.29722890e-02,\n",
            "        -3.42389911e-01, -3.44441324e-01,  7.95515478e-02,\n",
            "        -2.41783932e-01, -2.19764397e-01,  3.29285741e-01,\n",
            "        -3.16673160e-01, -2.36355007e-01, -1.99123040e-01,\n",
            "         3.00477147e-01, -6.20906688e-02,  4.90572453e-02,\n",
            "         7.17871729e-03,  1.54543355e-01,  1.62161320e-01,\n",
            "        -1.38507798e-01, -7.96924680e-02,  1.25686191e-02,\n",
            "        -8.63346308e-02,  1.71021745e-01,  1.34600982e-01,\n",
            "        -2.76980460e-01, -3.94101024e-01,  1.11486755e-01,\n",
            "         1.90519676e-01, -9.07556266e-02,  2.02844918e-01,\n",
            "        -1.92716599e-01,  1.98977098e-01, -2.09687084e-01,\n",
            "         2.45142099e-03, -1.21546723e-02],\n",
            "       [-2.27361172e-01,  1.03389934e-01,  2.86935985e-01,\n",
            "        -3.36020887e-01,  2.61027161e-02,  9.63638425e-02,\n",
            "        -3.65055464e-02, -3.05338234e-01, -1.57028303e-01,\n",
            "        -3.36621016e-01,  1.34550959e-01,  2.54088223e-01,\n",
            "        -5.90637177e-02, -3.29736695e-02, -1.45883724e-01,\n",
            "         1.07324660e-01, -1.43245280e-01, -2.22638041e-01,\n",
            "         8.30032155e-02, -2.83022281e-02,  1.66776165e-01,\n",
            "        -2.18657702e-02,  1.42582525e-02,  1.44451335e-01,\n",
            "         9.72660184e-02, -1.09279342e-01,  1.72479033e-01,\n",
            "        -1.55813411e-01,  6.66925609e-02,  2.79428631e-01,\n",
            "         2.53369212e-01,  3.13104004e-01, -5.06289676e-03,\n",
            "         9.00637433e-02, -1.47066176e-01],\n",
            "       [ 4.59086671e-02, -1.05566252e-02, -3.37479085e-01,\n",
            "        -4.84729037e-02, -2.65851527e-01,  2.13240340e-01,\n",
            "         1.26373172e-01, -3.53658274e-02,  6.94460571e-02,\n",
            "         2.80698895e-01,  1.97414339e-01, -1.40047207e-01,\n",
            "        -2.08607391e-01, -1.49793178e-01,  1.07408367e-01,\n",
            "         2.53692359e-01, -2.75744468e-01, -5.39173111e-02,\n",
            "         1.61036789e-01, -9.28437933e-02,  6.89111724e-02,\n",
            "        -3.65817547e-01, -1.87659338e-01,  4.14446034e-02,\n",
            "        -2.83114970e-01, -6.73896000e-02, -2.22271368e-01,\n",
            "         1.46177813e-01, -1.59491658e-01, -6.47923723e-02,\n",
            "        -5.09542935e-02,  1.61751863e-02,  1.05128646e-01,\n",
            "         4.96739820e-02, -1.98062629e-01],\n",
            "       [ 4.09087017e-02, -1.22117922e-01, -4.43516195e-01,\n",
            "        -9.65363160e-03, -2.36320451e-01, -5.95231541e-02,\n",
            "         2.03038137e-02, -2.57144064e-01,  1.21591933e-01,\n",
            "        -2.45784581e-01,  2.74003327e-01, -7.82091990e-02,\n",
            "        -1.39419198e-01, -3.03092897e-01,  1.88056886e-01,\n",
            "        -2.73104519e-01,  3.78871441e-01, -3.12628031e-01,\n",
            "        -8.72868448e-02,  2.81588733e-01, -1.37538359e-01,\n",
            "         1.53955713e-01, -1.66183695e-01,  1.65286750e-01,\n",
            "        -1.02195680e-01, -2.52806216e-01,  2.02947557e-01,\n",
            "        -2.53750592e-01,  9.74502135e-03,  3.81435305e-02,\n",
            "         1.50504604e-01, -2.31164624e-03, -1.40159205e-01,\n",
            "         3.37612092e-01,  1.81277305e-01],\n",
            "       [ 1.17882960e-01,  4.54195499e-01, -4.15411979e-01,\n",
            "         1.67455822e-01,  2.40043133e-01, -3.94096762e-01,\n",
            "         4.65279296e-02, -1.21510670e-01,  4.97534312e-02,\n",
            "        -1.59590960e-01, -4.42989767e-01, -5.18886447e-02,\n",
            "        -1.09854333e-01,  7.64173781e-03, -2.19033752e-02,\n",
            "        -6.11930192e-02, -2.29885191e-01, -8.41274187e-02,\n",
            "        -5.33568449e-02,  3.93691301e-01,  3.67951423e-01,\n",
            "        -2.54296541e-01, -4.73922417e-02,  1.80650637e-01,\n",
            "         2.22469598e-01, -2.38627478e-01,  9.78908315e-02,\n",
            "         2.39779264e-01,  3.05307746e-01, -5.94084375e-02,\n",
            "         4.03273255e-01,  2.68231034e-01,  3.35319191e-01,\n",
            "        -2.36531869e-02,  1.65559724e-01],\n",
            "       [-1.83599979e-01,  2.58216232e-01,  7.22663328e-02,\n",
            "         1.66710466e-01,  2.78227895e-01,  4.54608388e-02,\n",
            "         2.92261750e-01, -1.94669798e-01, -2.08297357e-01,\n",
            "         1.95026845e-01,  3.78222376e-01,  8.72256383e-02,\n",
            "         3.44816804e-01, -4.65343073e-02, -1.67320073e-01,\n",
            "        -1.38708144e-01, -3.42426337e-02,  1.78674608e-01,\n",
            "        -9.14734080e-02,  2.60957897e-01, -1.02112964e-01,\n",
            "        -9.23467055e-02,  8.22952688e-02, -1.44084349e-01,\n",
            "         6.81370422e-02, -1.78702980e-01,  2.36809552e-01,\n",
            "         1.46525707e-02, -2.85931766e-01,  1.31112143e-01,\n",
            "         1.90446422e-01,  6.89885616e-02, -9.84412879e-02,\n",
            "         7.85352103e-03, -3.11790943e-01],\n",
            "       [ 1.59083724e-01,  2.09519520e-01, -3.69786136e-02,\n",
            "        -9.01365057e-02,  6.26843423e-02, -1.93950400e-01,\n",
            "        -4.67030555e-01,  4.96853702e-02, -3.48732233e-01,\n",
            "        -2.85445184e-01, -9.37241465e-02,  2.55036056e-01,\n",
            "         1.97061196e-01,  2.93889970e-01, -2.30873734e-01,\n",
            "        -4.01487410e-01,  5.34000099e-01, -1.15998410e-01,\n",
            "         1.27065152e-01, -1.82117581e-01, -3.57409120e-01,\n",
            "        -4.06374857e-02, -1.10685028e-01,  1.61107838e-01,\n",
            "        -3.66650164e-01, -2.82898247e-01, -1.57175702e-04,\n",
            "         2.72961169e-01,  2.21982569e-01,  1.25084504e-01,\n",
            "        -1.15887485e-02, -3.55862081e-01,  4.10649180e-01,\n",
            "         1.60161898e-01, -1.85579702e-01]], dtype=float32)>, <tf.Variable 'dense_36/bias:0' shape=(35,) dtype=float32, numpy=\n",
            "array([ 0.05943476, -0.08967672, -0.09255315, -0.07919447, -0.03996721,\n",
            "       -0.29346058,  0.03855245,  0.06501684, -0.3612532 ,  0.2069936 ,\n",
            "       -0.19953543, -0.10371543, -0.2689008 , -0.12729383,  0.23130107,\n",
            "        0.09194449, -0.24352647, -0.14422826, -0.21686949, -0.20827624,\n",
            "        0.09726465,  0.27659392,  0.54562   , -0.41844252, -0.05251882,\n",
            "        0.01076207, -0.15689528, -0.22129393, -0.10133215,  0.21674442,\n",
            "       -0.18497337,  0.08932433, -0.29403374,  0.14384703, -0.15802163],\n",
            "      dtype=float32)>, <tf.Variable 'dense_37/kernel:0' shape=(35, 35) dtype=float32, numpy=\n",
            "array([[ 0.07791428,  0.21974511,  0.06611773, ..., -0.05082442,\n",
            "         0.11461519, -0.14363328],\n",
            "       [-0.00168865,  0.01646885,  0.28112048, ..., -0.326357  ,\n",
            "        -0.1022635 , -0.15636237],\n",
            "       [ 0.02686066,  0.11265109, -0.05973886, ...,  0.27767152,\n",
            "        -0.26324037, -0.06928469],\n",
            "       ...,\n",
            "       [-0.27782473, -0.20273423,  0.2342577 , ...,  0.11486991,\n",
            "         0.21843767,  0.06877726],\n",
            "       [-0.06525023,  0.03614471,  0.20885232, ..., -0.4213379 ,\n",
            "        -0.209705  ,  0.01349327],\n",
            "       [ 0.0615174 ,  0.03145581, -0.14276199, ..., -0.19005409,\n",
            "         0.06670992,  0.09868906]], dtype=float32)>, <tf.Variable 'dense_37/bias:0' shape=(35,) dtype=float32, numpy=\n",
            "array([ 0.05810486, -0.12619454,  0.00111828, -0.12111151, -0.1251948 ,\n",
            "       -0.15483145, -0.15778211,  0.3097978 , -0.06170737, -0.03438729,\n",
            "       -0.03277132, -0.05447448,  0.10646044,  0.39520472, -0.12682185,\n",
            "       -0.14855152, -0.19116814,  0.14971253,  0.08260553, -0.04130015,\n",
            "       -0.22452301, -0.06065165, -0.06546514,  0.11847844,  0.15978584,\n",
            "       -0.03954273, -0.05265243, -0.09367536, -0.07652838, -0.03472063,\n",
            "        0.05941905, -0.06909449, -0.09435196, -0.05138631, -0.00247495],\n",
            "      dtype=float32)>, <tf.Variable 'dense_38/kernel:0' shape=(35, 35) dtype=float32, numpy=\n",
            "array([[-0.37446234, -0.12008477,  0.11976115, ..., -0.06481592,\n",
            "         0.24594994, -0.05669428],\n",
            "       [ 0.08940041,  0.06759045,  0.19835576, ...,  0.05769728,\n",
            "        -0.17000857, -0.1082477 ],\n",
            "       [-0.13374056, -0.1676351 ,  0.3147994 , ..., -0.11008896,\n",
            "        -0.15221538, -0.1571842 ],\n",
            "       ...,\n",
            "       [ 0.18461761,  0.37064767,  0.40843564, ...,  0.13299228,\n",
            "        -0.04490814, -0.21435533],\n",
            "       [ 0.09142321,  0.21870562,  0.00539677, ...,  0.29426944,\n",
            "        -0.14418481,  0.06350792],\n",
            "       [-0.24050072,  0.25053418,  0.05338639, ..., -0.06311243,\n",
            "         0.09764468, -0.02875185]], dtype=float32)>, <tf.Variable 'dense_38/bias:0' shape=(35,) dtype=float32, numpy=\n",
            "array([-0.11738098,  0.01773067,  0.02554522, -0.0425009 ,  0.0717915 ,\n",
            "        0.02425988, -0.18969911, -0.2731921 , -0.07339138,  0.03370193,\n",
            "        0.01202495, -0.10503517, -0.09944052, -0.1056005 , -0.09466772,\n",
            "       -0.04918287,  0.04461363,  0.01017442, -0.12849368,  0.07655051,\n",
            "        0.03497057,  0.00518942, -0.03395227, -0.00081344, -0.04414887,\n",
            "        0.0324207 ,  0.01879221,  0.03024456,  0.00585306,  0.01627198,\n",
            "        0.05494992, -0.19776425,  0.0102848 ,  0.01648492,  0.03195515],\n",
            "      dtype=float32)>, <tf.Variable 'dense_39/kernel:0' shape=(35, 1) dtype=float32, numpy=\n",
            "array([[-1.9579314e-01],\n",
            "       [ 7.8238487e-01],\n",
            "       [ 2.9542020e-01],\n",
            "       [ 2.0501053e-02],\n",
            "       [-6.1782960e-02],\n",
            "       [ 2.9530856e-01],\n",
            "       [-2.7073452e-01],\n",
            "       [-6.8429494e-01],\n",
            "       [-2.0863459e-01],\n",
            "       [-3.5318360e-02],\n",
            "       [-2.3737530e-01],\n",
            "       [-3.5978839e-02],\n",
            "       [-2.1198401e-01],\n",
            "       [ 2.0794342e-04],\n",
            "       [ 4.7557880e-03],\n",
            "       [ 2.6022926e-01],\n",
            "       [-1.7000954e-01],\n",
            "       [-2.8205421e-02],\n",
            "       [-3.7080515e-03],\n",
            "       [ 5.2588600e-01],\n",
            "       [ 2.2239502e-01],\n",
            "       [-1.4193577e-01],\n",
            "       [ 1.8620370e-01],\n",
            "       [ 1.8984629e-01],\n",
            "       [ 6.9181167e-04],\n",
            "       [ 1.5727837e-01],\n",
            "       [ 7.7722526e-01],\n",
            "       [ 4.8825023e-01],\n",
            "       [ 2.1098353e-01],\n",
            "       [ 1.5034077e-01],\n",
            "       [ 4.0964830e-01],\n",
            "       [ 5.3662544e-01],\n",
            "       [ 2.0015813e-01],\n",
            "       [ 2.7305689e-01],\n",
            "       [-1.8237674e-01]], dtype=float32)>, <tf.Variable 'dense_39/bias:0' shape=(1,) dtype=float32, numpy=array([0.00825096], dtype=float32)>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFMf6h3G4T9g"
      },
      "source": [
        "# error_surface = np.reshape(np.array(errors), (x_range.shape[0], y_range.shape[0]))\n",
        "# _X, _Y = np.meshgrid(x_range, y_range, indexing='ij')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QvKeicnyOVI"
      },
      "source": [
        "from numpy import savetxt\n",
        "savetxt('weights.csv', weights[0], delimiter=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH-t9Fobz0sK"
      },
      "source": [
        "w1=pd.read_csv('weights.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "khVxo7hN0MRY",
        "outputId": "c75d18fc-c39d-4efe-ea9b-13e1d5ea464a"
      },
      "source": [
        "w1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-0dee9a7c86fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'w1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Il-Eheub0PlX",
        "outputId": "2c7e2967-9860-48ba-a78b-e264e422aa67"
      },
      "source": [
        "len(w1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    }
  ]
}